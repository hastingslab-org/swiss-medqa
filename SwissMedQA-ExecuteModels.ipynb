{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b14dddd1-025c-431f-9168-956777f7adf1",
   "metadata": {},
   "source": [
    "## Swiss MedQA - A study in LLMs answering medical questions in Swiss languages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e430b7-95c9-40fe-a454-b14d85d9d7f9",
   "metadata": {},
   "source": [
    "#### Process the question data to be executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e270b5f3-acbd-422a-a4de-2294a15487d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load question data \n",
    "import pandas as pd\n",
    "\n",
    "filename = \"dataset-20241228/MKDS_SwissMedQA_Spreadsheets_1024.xlsx\"\n",
    "sheetName = \"Spreadsheet 2 text only\"\n",
    "\n",
    "df = pd.read_excel(filename,sheet_name=sheetName, engine= 'openpyxl')\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e970e-be74-4bf5-97a1-0af8a95ae968",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load information about the questions\n",
    "questioninfosheetname = \"Spreadsheet 1\"\n",
    "df_questioninfo = pd.read_excel(filename,sheet_name=questioninfosheetname, engine= 'openpyxl')\n",
    "df_questioninfo.columns = df_questioninfo.columns.str.strip()\n",
    "df_questioninfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8355f9e-13ce-405b-bd9a-8cdfc5cce518",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questioninfo[\"Modality Type\"] = [\"text only\" if m == \"textonly\" else m.strip() for m in df_questioninfo[\"Modality Type\"]]\n",
    "\n",
    "df_questioninfo[ [\"Unique ID\",\"Modality Type\"] ].groupby(\"Modality Type\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7953b1-1e5c-4e34-a6ea-b1a456558ec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_questioninfo[ [\"Unique ID\",\"Modality Type\",\"Category (1=General medicine, 2=Surgery/Traumatology, 3=Pediatrics, 4=gynocology, 5=Public Health and others\"]].groupby([\"Modality Type\",\"Category (1=General medicine, 2=Surgery/Traumatology, 3=Pediatrics, 4=gynocology, 5=Public Health and others\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b8a10-1bde-4941-b061-5d0e1e3e2a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questioninfo[ [\"Unique ID\",\"Modality Type\",\"acute (=1) vs chronic (=0)\"]].groupby([\"Modality Type\",\"acute (=1) vs chronic (=0)\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2d85a7-9a38-41cb-b1ed-df6aac1073eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_questioninfo[ [\"Unique ID\",\"Modality Type\",\"Diagnosis (=1), Treatment (=2), Other(=3)\"]].groupby([\"Modality Type\",\"Diagnosis (=1), Treatment (=2), Other(=3)\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125b7e2a-a891-42bd-876f-9532cfb5be30",
   "metadata": {},
   "source": [
    "#### Set up language models for execution via APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831eb55d-6a11-4e2e-b7a5-33a0e766d1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for language model setup\n",
    "\n",
    "#from mlx_lm import load, generate\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "from openai import OpenAI\n",
    "import anthropic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ea3b2a-6579-4fc5-953d-22142f2a0000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the models that will be used in the study \n",
    "model_fullnames = {#\"llama32-3b\":\"mlx-community/Llama-3.2-3B-Instruct\",  # On server use: \"llama32-3b\":\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "                   #\"gpt35\":\"gpt-3.5-turbo\",\n",
    "                   #\"qwen72b\":\"Qwen/Qwen2.5-72B-Instruct\",\n",
    "                   #\"yi-34b\":\"01-ai/Yi-34B-Chat\",\n",
    "                   #\"llama31-70b\":\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
    "                   \"llama33-70b\":\"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "                   \"llama31-405b\":\"meta-llama/Meta-Llama-3.1-405B-Instruct\",\n",
    "                   \"deepseek-v3\":\"deepseek-ai/DeepSeek-V3\",\n",
    "                   #\"deepseek-r1\":\"deepseek-ai/DeepSeek-R1\",\n",
    "                   #\"mixtral-8x22b\":\"mistralai/Mixtral-8x22B-Instruct-v0.1\",\n",
    "                   \"claude-sonnet-3.7\":\"claude-3-7-sonnet-20250219\",\n",
    "                   #\"claude-haiku-3.5\":\"claude-3-5-haiku-20241022\",\n",
    "                   \"gpt4o\":\"gpt-4o\",   \n",
    "                   #\"o3-mini\":\"o3-mini\",  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe81530-9e1f-4a9c-b0fa-36e53eff89ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the models\n",
    "import os\n",
    "model = None\n",
    "modelname = None\n",
    "client = None\n",
    "tokenizer = None\n",
    "\n",
    "def generateFromPrompt(modeln, systemMessage, prompt):\n",
    "    global modelname\n",
    "    global model\n",
    "    global client\n",
    "    global tokenizer\n",
    "    if modelname is None or modelname != modeln:\n",
    "        modelname = modeln\n",
    "        if modelname in [ \"llama32-3b\" ]:  # Local model \n",
    "            model, tokenizer = load(model_fullnames[modelname])\n",
    "        elif modelname in [ \"gpt35\", \"gpt4o\" , \"o3-mini\" ]: # OpenAI models\n",
    "            client = OpenAI(\n",
    "                api_key=os.environ.get(\"OPENAI_KEY\"),\n",
    "            )\n",
    "        elif modelname in [\"claude-sonnet-3.7\",\"claude-haiku-3.5\"]: # Anthropic Models\n",
    "            client = anthropic.Anthropic(\n",
    "                api_key=os.environ.get(\"ANTHROPIC_KEY\")\n",
    "            )\n",
    "        else: # DeepInfra models\n",
    "            client = OpenAI(\n",
    "                api_key = os.environ.get(\"DEEPINFRA_KEY\"),\n",
    "                base_url=\"https://api.deepinfra.com/v1/openai\",\n",
    "            )\n",
    "    if modelname in [ \"llama32-3b\" ]:  # Local model \n",
    "        if hasattr(tokenizer, \"apply_chat_template\") and tokenizer.chat_template is not None:\n",
    "            messages = [{\"role\": \"system\", \"content\": systemMessage},\n",
    "                {\"role\": \"user\", \"content\": prompt}]\n",
    "            prompt = tokenizer.apply_chat_template(\n",
    "                messages, tokenize=False, add_generation_prompt=True\n",
    "            )\n",
    "            response = generate(model, tokenizer, prompt=prompt, verbose=False)\n",
    "            return response\n",
    "        else:\n",
    "            print(\"Error! Local model appears not set up correctly\")\n",
    "    elif modelname in [\"claude-sonnet-3.7\",\"claude-haiku-3.5\"]: # Anthropic models\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "          ]\n",
    "        response = client.messages.create(\n",
    "            model=model_fullnames[modelname],\n",
    "            messages=messages,\n",
    "            system=systemMessage,\n",
    "            max_tokens=10,\n",
    "        )\n",
    "        return response.content[0].text\n",
    "    else: # Via one of the OpenAI APIs\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": systemMessage},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "          ]\n",
    "        completion = client.chat.completions.create(\n",
    "            model=model_fullnames[modelname],\n",
    "            messages=messages,\n",
    "        )\n",
    "        response=completion.choices[0].message.content\n",
    "        return response\n",
    "\n",
    "\n",
    "res = generateFromPrompt(\"llama33-70b\",\"You are a helpful assistant.\",\"Hello!\")\n",
    "print(res)\n",
    "res = generateFromPrompt(\"o3-mini\",\"You are a helpful assistant.\",\"Hello!\")\n",
    "print(res)\n",
    "res = generateFromPrompt(\"claude-sonnet-3.7\",\"You are a helpful assistant.\",\"Hello!\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71657884-d4cd-4b38-ba65-db15ee3cc5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the processing functions to answer the questions and clean the responses\n",
    "def processQuestion(modelName, systemMsg, promptTemplate, question, A, B, C, D, E):\n",
    "    userMsg = promptTemplate.format(question, A, B, C, D, E)\n",
    "    res = generateFromPrompt(modelName,systemMsg,userMsg)\n",
    "    return res\n",
    "\n",
    "def cleanResponse(response):\n",
    "    if not isinstance(response,str):\n",
    "        response = str(response)\n",
    "    if '-' in response: \n",
    "        response = response.split('-')[0]\n",
    "    response = response.strip()\n",
    "    return response\n",
    "\n",
    "import re\n",
    "\n",
    "def isCorrect(response,groundTruth):\n",
    "    if len(groundTruth)>1:\n",
    "        groundTruth = list(groundTruth)\n",
    "        response = clean = re.sub(r'[^\\w\\s]|\\s', '', response)\n",
    "        response = list(response)\n",
    "        return set(groundTruth) == set(response)\n",
    "    else: \n",
    "        return groundTruth == response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6324048a-3bc9-44a5-a303-c0f54d933c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prompt on a single question\n",
    "ENG_PROMPTS = True\n",
    "\n",
    "LANG_SYSTEM_MSGS = {\"en\": \"You are a helpful medical question answering assistant. Please carefully follow the exact instructions, return only the answer letter, and do not provide explanations.\",\n",
    "                    \"de\": \"Du bist ein hilfreicher Assistent bei der Beantwortung medizinischer Fragen. Bitte befolge die genauen Anweisungen sorgfältig, sende nur den Antwortbrief zurück und füge keine Erklärungen bei.\",\n",
    "                    \"fr\": \"Tu es un assistant qui répond à des questions médicales utiles. Merci de suivre scrupuleusement les instructions exactes, de ne renvoyer que la lettre de réponse et de ne pas fournir d'explications.\",\n",
    "                    \"it\": \"Sei un utile assistente medico che risponde alle domande. Ti preghiamo di seguire attentamente le istruzioni, di restituire solo la lettera di risposta e di non fornire spiegazioni.\"}\n",
    "\n",
    "LANG_PROMPT_TEMPLS = {\"en\": \"Please answer the following multiple choice question by selecting the correct response option or options. \\\n",
    "    Question: {}. Response options: A - {}, B - {}, C - {}, D - {}, E - {}. Return only the letter or letters (A,B,C,D,E) corresponding to the correct answer. The correct answer to the question is: \",\n",
    "                      \"de\": \"Bitte beantworte die folgende Multiple-Choice-Frage, indem du die richtige(n) Antwortoption(en) auswählst. \\\n",
    "    Frage: {}. Antwortoptionen: A - {}, B - {}, C - {}, D - {}, E - {}. Gib nur den/die Buchstaben (A, B, C, D, E) an, die der richtigen Antwort entsprechen. Die richtige Antwort auf die Frage lautet:\",\n",
    "                      \"fr\": \"Réponds à la question à choix multiples suivante en sélectionnant la ou les bonnes options de réponse. \\\n",
    "    Question : {}. Options de réponse : A - {}, B - {}, C - {}, D - {}, E - {}. Ne renvoie que la ou les lettres (A,B,C,D,E) correspondant à la bonne réponse. La bonne réponse à la question est :\",\n",
    "                      \"it\": \"Rispondi alla seguente domanda a scelta multipla selezionando la o le opzioni di risposta corrette. \\\n",
    "    Domanda: {}. Opzioni di risposta: A - {}, B - {}, C - {}, D - {}, E - {}. Riporta solo la lettera o le lettere (A,B,C,D,E) corrispondenti alla risposta corretta. La risposta corretta alla domanda è:\" }\n",
    "\n",
    "def getSystemMessage(language):\n",
    "    if ENG_PROMPTS:\n",
    "        return LANG_SYSTEM_MSGS['en'] # Always use the English prompts\n",
    "    else: \n",
    "        return LANG_SYSTEM_MSGS[language]\n",
    "\n",
    "def getPromptTemplate(language): \n",
    "    if ENG_PROMPTS:\n",
    "        return LANG_PROMPT_TEMPLS['en'] # Always prompt in English\n",
    "    else: \n",
    "        return LANG_PROMPT_TEMPLS[language]\n",
    "        \n",
    "for model_name in model_fullnames: # test all models\n",
    "    response = processQuestion(model_name, getSystemMessage('it'), getPromptTemplate('it'), \"How many fingers does a human hand have?\",\"Z\",\"3\",\"2\",\"5\",\"4\")\n",
    "    print(model_name,response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867ebeaf-6f96-4501-b473-bcd724c69cf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare the results storage - either a new file (if doing a new run) or reload (if starting again half way)\n",
    "RELOAD = True\n",
    "resultsDirectory = \"../results/results-20250308/\"\n",
    "resultsFilename = \"dfresults.csv\"\n",
    "\n",
    "import os\n",
    "os.makedirs(resultsDirectory, exist_ok=True)\n",
    "\n",
    "if RELOAD: \n",
    "    # Load from stored file \n",
    "    df_results = pd.read_csv(resultsDirectory+resultsFilename,index_col=0)\n",
    "    # Remove calculated columns\n",
    "    df_results.drop([\"DE_clean\", \"FR_clean\", \"IT_clean\",\"DE_correct\",\"FR_correct\",\"IT_correct\",\"AnswerType\",\"Category (1=General medicine, 2=Surgery/Traumatology, 3=Pediatrics, 4=gynocology, 5=Public Health and others\",\"acute (=1) vs chronic (=0)\",\"Diagnosis (=1), Treatment (=2), Other(=3)\"],axis=1,inplace=True,errors='ignore')\n",
    "else: \n",
    "    df_results = pd.DataFrame(columns= list(df.columns.values)+ [\"Model\",\"DE\",\"FR\",\"IT\"])\n",
    "\n",
    "print(df_results.shape)\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568d9ecd-6661-417f-8c1a-9dc6752ee1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# MAIN EXECUTION: Run the models and collect the results. This is going to be quite slow. \n",
    "for eng_prompts in [True,False]:\n",
    "    ENG_PROMPTS = eng_prompts\n",
    "    \n",
    "    for modeln in model_fullnames.keys():\n",
    "        for i in range(10): \n",
    "            \n",
    "            matching_rows = ((df_results['Model'] == modeln) & (df_results['EngPrompt'] == eng_prompts) & (df_results['Run'] == i)).any()\n",
    "            if matching_rows:\n",
    "                print(\"Not executing model:\", modeln, \"EngPrompt:\",eng_prompts,\"Run:\",i,\"as already non-empty.\")\n",
    "            else: \n",
    "                print(\"Starting execution of model:\", modeln, \"EngPrompt:\",eng_prompts,\"Run:\",i)\n",
    "                rowResults = {\"EngPrompt\":eng_prompts,\"Model\":modeln,\"Run\":i}\n",
    "\n",
    "                for index, row in df.iterrows():\n",
    "                    qno = row[\"Question Set\"]\n",
    "                    rowResults.update(row)\n",
    "\n",
    "                    for language in ['de','fr','it']:\n",
    "                        question = row[\"Question \"+language]\n",
    "                        optA = row[\"Answer A \"+language]\n",
    "                        optB = row[\"Answer B \"+language]\n",
    "                        optC = row[\"Answer C \"+language]\n",
    "                        optD = row[\"Answer D \"+language]\n",
    "                        optE = row[\"Answer E \"+language]\n",
    "\n",
    "                        # Run the LLM\n",
    "                        result = processQuestion(modeln,getSystemMessage(language),getPromptTemplate(language),question,optA,optB,optC,optD,optE)\n",
    "                        #print(index, \" : \",language,\" :\",question,\"----->\",result)\n",
    "                        rowResults[language.upper()] = result\n",
    "\n",
    "                    #print(rowResults)\n",
    "                    df_results.loc[len(df_results)] = rowResults\n",
    "                \n",
    "                df_results.to_csv(resultsDirectory+resultsFilename)    \n",
    "                print(f\"{datetime.datetime.now().strftime('%H:%M:%S')} Finished execution of (Eng?{eng_prompts}), model {modeln}, run {i}. Results table size: {df_results.shape} \")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e100db72-17cb-49f1-a8bd-ba093fdb7f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and save the results  \n",
    "import os\n",
    "\n",
    "for language in [\"DE\",\"FR\",\"IT\"]:\n",
    "    df_results[language+\"_clean\"] = [cleanResponse(c) for c in df_results[language] ]\n",
    "\n",
    "for language in [\"DE\",\"FR\",\"IT\"]:\n",
    "    df_results[language+\"_correct\"] = [isCorrect(c,g) for c,g in zip(df_results[language+\"_clean\"],df_results[\"MC modality\"]) ]\n",
    "\n",
    "\n",
    "\n",
    "# Add columns for additional question information - Answer Type MC single (0) or multiple (1) choices\n",
    "df_results[\"AnswerType\"] = [1 if len(g)>1 else 0 for g in df_results[\"MC modality\"] ]\n",
    "\n",
    "# Add columns for question information - Question category\n",
    "# Category (1=General medicine, 2=Surgery/Traumatology, 3=Pediatrics, 4=gynocology, 5=Public Health and others\n",
    "df_results = df_results.merge(df_questioninfo[ [\"Unique ID\", \"Category (1=General medicine, 2=Surgery/Traumatology, 3=Pediatrics, 4=gynocology, 5=Public Health and others\"] ], on=\"Unique ID\", how=\"left\")\n",
    "\n",
    "\n",
    "# Add the columns for the additional question information\n",
    "# acute (=1) vs chronic (=0) \tDiagnosis (=1), Treatment (=2), Other(=3)\n",
    "df_results = df_results.merge(df_questioninfo[ [\"Unique ID\", \"acute (=1) vs chronic (=0)\", \"Diagnosis (=1), Treatment (=2), Other(=3)\"] ], on=\"Unique ID\", how=\"left\")\n",
    "\n",
    "\n",
    "# Save the augmented results file with the previously specified directory and file name. \n",
    "df_results.to_csv(resultsDirectory+resultsFilename+\"-clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28379e82-8d3b-436c-9931-0e08c6bd22be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (llms)",
   "language": "python",
   "name": "llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
